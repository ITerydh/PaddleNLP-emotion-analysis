# PaddleNLP-æƒ…æ„Ÿåˆ†æ
PaddleNLPä¹‹ä¸ƒä¸ªæ•°æ®é›†çš„æƒ…æ„Ÿåˆ†æ

é¡¹ç›®åœ°å€å·²ç»æ”¾åœ¨[åŸºäº[å®è·µè¯¾5-æƒ…æ„Ÿåˆ†æbaseline]ä¼˜åŒ–çš„æƒ…æ„Ÿåˆ†æ](https://aistudio.baidu.com/aistudio/projectdetail/2104045)

# è‡ªç„¶è¯­è¨€å¤„ç†ä¹‹æƒ…æ„Ÿåˆ†æå®ç°
è¿™é‡Œç”¨é£æ¡¨çš„é«˜å±‚APIå¿«é€Ÿæ­å»ºæ¨¡å‹å®ç°æƒ…æ„Ÿåˆ†ææ¯”èµ›çš„ç»“æœçš„æäº¤ã€‚å…·ä½“çš„åŸç†å’Œåˆ†æè¯·å‚è€ƒ[ã€NLPæ‰“å¡è¥ã€å®è·µè¯¾5ï¼šæ–‡æœ¬æƒ…æ„Ÿåˆ†æ](https://aistudio.baidu.com/aistudio/projectdetail/1968542?channelType=0&channel=0)ã€‚ä»¥ä¸‹å°†åˆ†ä¸‰éƒ¨åˆ†ï¼šå¥å­çº§æƒ…æ„Ÿåˆ†æï¼ˆNLPCC14-SC,ChnSentiCorpï¼‰ï¼›ç›®æ ‡çº§æƒ…æ„Ÿåˆ†æï¼ˆSE-ABSA16_PHNS,SE-ABSA16_CAMEï¼‰ï¼›ä»¥åŠè§‚ç‚¹æŠ½å–ï¼ˆCOTE-BDï¼ŒCOTE-DPï¼ŒCOTE-MFWï¼‰ã€‚

é¡¹ç›®çš„ä½¿ç”¨éå¸¸ç®€å•ï¼Œæ›´æ”¹ç›¸åº”ç« èŠ‚çš„data_nameï¼Œå¹¶è‡ªå·±è°ƒæ•´batch_sizeå’Œepochsç­‰ä»¥è¾¾åˆ°æœ€ä½³çš„è®­ç»ƒæ•ˆæœï¼Œå¹¶è¿è¡Œç›¸åº”ç« èŠ‚çš„æ‰€æœ‰ä»£ç å³å¯å¾—åˆ°å¯¹åº”æ•°æ®é›†çš„é¢„æµ‹ç»“æœã€‚æ‰€æœ‰æ•°æ®é¢„æµ‹å®Œæˆåï¼Œä¸‹è½½submissionæ–‡ä»¶å¤¹æäº¤å³å¯ã€‚

## åŸºäºåŸbaselineä¸Šçš„æ›´æ”¹ç‚¹
1. æ›´æ”¹äº†å­¦ä¹ ç‡
2. æ›´æ”¹äº†epoch
3. æ·»åŠ äº†é˜²æ­¢è¿‡æ‹Ÿåˆçš„æ­£åˆ™åŒ–é¡¹
4. æ·»åŠ äº†æƒ…æ„Ÿåˆ†ææ•°æ®é›†ï¼ˆå»é™¤äº†åŸæœ‰çš„datasetsï¼Œé˜²æ­¢ä¿å­˜ç‰ˆæœ¬æ—¶å¿˜è®°è€Œä¸¢å¤±æ•°æ®é›†ï¼Œæ­¤ç‚¹ä¸æˆç»©æ— å…³ï¼‰

æœ€ç»ˆå›¢é˜Ÿä¸ƒä¸ªæ•°æ®é›†çš„é¡¹ç›®æ€»åˆ†è¾¾åˆ°äº†0.81å·¦å³

## å»ºè®®
1. è·‘ä¹‹å‰ï¼Œåœ¨å·¦ä¾§çª—å£**æ–°å»ºä¸€ä¸ªsubmissionæ–‡ä»¶å¤¹**ï¼Œä¸ç„¶åç»­ä¼šæŠ¥é”™ï¼Œé‡åˆ°å°±æ‡‚äº† 
2. æ¯è·‘ä¸€ä¸ªæ•°æ®é›†ï¼Œé‡å¯ä¸€æ¬¡é¡¹ç›®ï¼Œé˜²æ­¢æ˜¾å­˜æº¢å‡ºã€‚
3. å°†æ¯ä¸ªæ•°æ®é›†è‡ªå·±æ–°å»ºä¸€ä¸ªæ–‡ä»¶è¿›è¡Œå­˜å‚¨ç”Ÿæˆçš„æ¨¡å‹ï¼Œé˜²æ­¢æ‰€æœ‰çš„æ•°æ®é›†çš„æ¨¡å‹åœ¨ä¸€å—æ··ä¹±ã€‚


```python
!pip install --upgrade paddlenlp -i https://pypi.org/simple 
```

    Collecting paddlenlp
    [?25l  Downloading https://files.pythonhosted.org/packages/63/7a/e6098c8794d7753470071f58b07843824c40ddbabe213eae458d321d2dbe/paddlenlp-2.0.3-py3-none-any.whl (451kB)
    [K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 460kB 26kB/s eta 0:00:012
    [?25hRequirement already satisfied, skipping upgrade: visualdl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.1.1)
    Requirement already satisfied, skipping upgrade: more-itertools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < "3.8"->pre-commit->visualdl->paddlenlp) (7.2.0)
    Installing collected packages: paddlenlp
      Found existing installation: paddlenlp 2.0.1
        Uninstalling paddlenlp-2.0.1:
          Successfully uninstalled paddlenlp-2.0.1
    Successfully installed paddlenlp-2.0.3


## 1. å¥å­çº§æƒ…æ„Ÿåˆ†æ
å¥å­çº§æƒ…æ„Ÿåˆ†ææ˜¯é’ˆå¯¹è¾“å…¥çš„ä¸€æ®µè¯ï¼Œåˆ¤æ–­å…¶æ„Ÿæƒ…å€¾å‘ï¼Œä¸€èˆ¬ä¸ºç§¯æï¼ˆ1ï¼‰æˆ–æ¶ˆæï¼ˆ0ï¼‰ã€‚

### 1.0 è½½å…¥æ¨¡å‹å’ŒTokenizer


```python
import paddlenlp
from paddlenlp.transformers import SkepForSequenceClassification, SkepTokenizer
```

### 1.1 æ•°æ®å¤„ç†
è™½ç„¶ä¸€äº›æ•°æ®é›†åœ¨PaddleNLPå·²å­˜åœ¨ï¼Œä½†æ˜¯ä¸ºäº†æ•°æ®å¤„ç†ä¸Šçš„ä¸€è‡´æ€§ï¼Œè¿™é‡Œç»Ÿä¸€ä»ä¸Šä¼ çš„datasetsä¸­å¤„ç†ã€‚å¯¹äºPaddleNLPå·²å­˜åœ¨çš„æ•°æ®é›†ï¼Œå¼ºçƒˆå»ºè®®ç›´æ¥ç”¨APIè°ƒç”¨ï¼Œéå¸¸æ–¹ä¾¿ã€‚


```python
# è§£å‹æ•°æ®
!unzip -o data/data95319/ChnSentiCorp
!unzip -o data/data95319/NLPCC14-SC
```

    Archive:  data/data95319/ChnSentiCorp.zip
      inflating: ChnSentiCorp/License.pdf  
      inflating: ChnSentiCorp/dev.tsv    
      inflating: ChnSentiCorp/test.tsv   
      inflating: ChnSentiCorp/train.tsv  
    Archive:  data/data95319/NLPCC14-SC.zip
      inflating: NLPCC14-SC/License.pdf  
      inflating: NLPCC14-SC/test.tsv     
      inflating: NLPCC14-SC/train.tsv    


æ•°æ®å†…éƒ¨ç»“æ„è§£æï¼š

```
ChnSentiCorp:

train: 
label		text_a
0		æˆ¿é—´å¤ªå°ã€‚å…¶ä»–çš„éƒ½ä¸€èˆ¬ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚
1		è½»ä¾¿ï¼Œæ–¹ä¾¿æºå¸¦ï¼Œæ€§èƒ½ä¹Ÿä¸é”™ï¼Œèƒ½æ»¡è¶³å¹³æ—¶çš„å·¥ä½œéœ€è¦ï¼Œå¯¹å‡ºå·®äººå‘˜æ¥è¯´éå¸¸ä¸é”™

dev:
qid		label		text_a
0		1		é€™é–“é…’åº—ç’°å¢ƒå’Œæœå‹™æ…‹åº¦äº¦ç®—ä¸éŒ¯,ä½†æˆ¿é–“ç©ºé–“å¤ªå°~...

test:
qid		text_a
0		è¿™ä¸ªå®¾é¦†æ¯”è¾ƒé™ˆæ—§äº†ï¼Œç‰¹ä»·çš„æˆ¿é—´ä¹Ÿå¾ˆä¸€èˆ¬ã€‚æ€»ä½“æ¥è¯´ä¸€èˆ¬
...		...


NLPCC14-SC:

train:
label		text_a
1		è¯·é—®è¿™æœºä¸æ˜¯æœ‰ä¸ªé¥æ§å™¨çš„å—ï¼Ÿ
0		å…¨æ˜¯å¤§é“ç†å•Š

test:
qid		text_a
0		æˆ‘ç»ˆäºæ‰¾åˆ°åŒé“ä¸­äººå•¦ï½ï½ï½ï½ä»åˆä¸­å¼€å§‹ï¼Œæˆ‘å°±...
...		...
```

ä»ä¸Šå¯ä»¥çœ‹å‡ºä¸¤ä¸ªæ•°æ®é›†å¯ä»¥å®šä¹‰ä¸€è‡´çš„è¯»å–æ–¹å¼ï¼Œä½†æ˜¯NLPCC14-SCæ²¡æœ‰devæ•°æ®é›†ï¼Œå› æ­¤ä¸å†å®šä¹‰devæ•°æ®


```python
# å¾—åˆ°æ•°æ®é›†å­—å…¸
def open_func(file_path):
    return [line.strip() for line in open(file_path, 'r', encoding='utf8').readlines()[1:] if len(line.strip().split('\t')) >= 2]

data_dict = {'chnsenticorp': {'test': open_func('ChnSentiCorp/test.tsv'),
                              'dev': open_func('ChnSentiCorp/dev.tsv'),
                              'train': open_func('ChnSentiCorp/train.tsv')},
             'nlpcc14sc': {'test': open_func('NLPCC14-SC/test.tsv'),
                           'train': open_func('NLPCC14-SC/train.tsv')}}
```

### 1.2 å®šä¹‰æ•°æ®è¯»å–å™¨


```python
# å®šä¹‰æ•°æ®é›†
from paddle.io import Dataset, DataLoader
from paddlenlp.data import Pad, Stack, Tuple
import numpy as np
label_list = [0, 1]

# æ³¨æ„ï¼Œç”±äºtoken typeåœ¨æ­¤é¡¹ä»»åŠ¡ä¸­å¹¶æ²¡æœ‰èµ·ä½œç”¨ï¼Œå› æ­¤è¿™é‡Œä¸å†è€ƒè™‘ï¼Œè®©æ¨¡å‹è‡ªè¡Œå¡«å……ã€‚
class MyDataset(Dataset):
    def __init__(self, data, tokenizer, max_len=512, for_test=False):
        super().__init__()
        self._data = data
        self._tokenizer = tokenizer
        self._max_len = max_len
        self._for_test = for_test
    
    def __len__(self):
        return len(self._data)
    
    def __getitem__(self, idx):
        samples = self._data[idx].split('\t')
        label = samples[-2]
        text = samples[-1]
        label = int(label)
        text = self._tokenizer.encode(text, max_seq_len=self._max_len)['input_ids']
        if self._for_test:
            return np.array(text, dtype='int64')
        else:
            return np.array(text, dtype='int64'), np.array(label, dtype='int64')

def batchify_fn(for_test=False):
    if for_test:
        return lambda samples, fn=Pad(axis=0, pad_val=tokenizer.pad_token_id): np.row_stack([data for data in fn(samples)])
    else:
        return lambda samples, fn=Tuple(Pad(axis=0, pad_val=tokenizer.pad_token_id),
                                        Stack()): [data for data in fn(samples)]


def get_data_loader(data, tokenizer, batch_size=32, max_len=512, for_test=False):
    dataset = MyDataset(data, tokenizer, max_len, for_test)
    shuffle = True if not for_test else False
    data_loader = DataLoader(dataset=dataset, batch_size=batch_size, collate_fn=batchify_fn(for_test), shuffle=shuffle)
    return data_loader
```

### 1.3 æ¨¡å‹æ­å»ºå¹¶è¿›è¡Œè®­ç»ƒ
æ¨¡å‹éå¸¸ç®€å•ï¼Œæˆ‘ä»¬åªéœ€è¦è°ƒç”¨å¯¹åº”çš„åºåˆ—åˆ†ç±»å·¥å…·å°±è¡Œäº†ã€‚ä¸ºäº†æ–¹ä¾¿è®­ç»ƒï¼Œç›´æ¥ç”¨é«˜å±‚API Modelå®Œæˆè®­ç»ƒã€‚


```python
import paddle
from paddle.static import InputSpec

# æ¨¡å‹å’Œåˆ†è¯
model = SkepForSequenceClassification.from_pretrained('skep_ernie_1.0_large_ch', num_classes=2)
tokenizer = SkepTokenizer.from_pretrained('skep_ernie_1.0_large_ch')

# å‚æ•°è®¾ç½®
data_name = 'nlpcc14sc'  # æ›´æ”¹æ­¤é€‰é¡¹æ”¹å˜æ•°æ®é›†

## è®­ç»ƒç›¸å…³
epochs = 10
learning_rate = 5e-6
batch_size = 8
max_len = 512

## æ•°æ®ç›¸å…³
train_dataloader = get_data_loader(data_dict[data_name]['train'], tokenizer, batch_size, max_len, for_test=False)
if data_name == 'chnsenticorp':
    dev_dataloader = get_data_loader(data_dict[data_name]['dev'], tokenizer, batch_size, max_len, for_test=False)
else:
    dev_dataloader = None

input = InputSpec((-1, -1), dtype='int64', name='input')
label = InputSpec((-1, 2), dtype='int64', name='label')
model = paddle.Model(model, [input], [label])

# æ¨¡å‹å‡†å¤‡
# åŠ å…¥è¿‡æ‹Ÿåˆ æ­£åˆ™åŒ– 
optimizer = paddle.optimizer.Adam(learning_rate=learning_rate,weight_decay=paddle.regularizer.L2Decay(coeff=1e-5),parameters=model.parameters())
model.prepare(optimizer, loss=paddle.nn.CrossEntropyLoss(), metrics=[paddle.metric.Accuracy()])
```

    [2021-06-22 12:30:47,799] [    INFO] - Downloading https://paddlenlp.bj.bcebos.com/models/transformers/skep/skep_ernie_1.0_large_ch.pdparams and saved to /home/aistudio/.paddlenlp/models/skep_ernie_1.0_large_ch
    [2021-06-22 12:30:47,859] [    INFO] - Downloading skep_ernie_1.0_large_ch.pdparams from https://paddlenlp.bj.bcebos.com/models/transformers/skep/skep_ernie_1.0_large_ch.pdparams
    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1238309/1238309 [00:39<00:00, 31211.08it/s]
    /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1297: UserWarning: Skip loading for classifier.weight. classifier.weight is not found in the provided dict.
      warnings.warn(("Skip loading for {}. ".format(key) + str(err)))
    /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1297: UserWarning: Skip loading for classifier.bias. classifier.bias is not found in the provided dict.
      warnings.warn(("Skip loading for {}. ".format(key) + str(err)))
    [2021-06-22 12:31:39,146] [    INFO] - Downloading skep_ernie_1.0_large_ch.vocab.txt from https://paddlenlp.bj.bcebos.com/models/transformers/skep/skep_ernie_1.0_large_ch.vocab.txt
    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:00<00:00, 2940.11it/s]



```python
# å¼€å§‹è®­ç»ƒ
model.fit(train_dataloader, dev_dataloader, batch_size, epochs, eval_freq=5, save_freq=5, save_dir='./checkpoints', log_freq=200)
```

    The loss value printed in the log is the current step, and the metric is the average value of previous steps.
    Epoch 1/10


    /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working
      return (isinstance(seq, collections.Sequence) and


### 1.4 é¢„æµ‹å¹¶ä¿å­˜


```python
# å¯¼å…¥é¢„è®­ç»ƒæ¨¡å‹
checkpoint_path = './checkpoints/final'  # å¡«å†™é¢„è®­ç»ƒæ¨¡å‹çš„ä¿å­˜è·¯å¾„

model = SkepForSequenceClassification.from_pretrained('skep_ernie_1.0_large_ch', num_classes=2)
input = InputSpec((-1, -1), dtype='int64', name='input')
model = paddle.Model(model, input)
model.load(checkpoint_path)

# å¯¼å…¥æµ‹è¯•é›†
test_dataloader = get_data_loader(data_dict[data_name]['test'], tokenizer, batch_size, max_len, for_test=True)
# é¢„æµ‹ä¿å­˜

save_file = {'chnsenticorp': './submission/ChnSentiCorp.tsv', 'nlpcc14sc': './submission/NLPCC14-SC.tsv'}
predicts = []
for batch in test_dataloader:
    predict = model.predict_batch(batch)
    predicts += predict[0].argmax(axis=-1).tolist()

with open(save_file[data_name], 'w', encoding='utf8') as f:
    f.write("index\tprediction\n")
    for idx, sample in enumerate(data_dict[data_name]['test']):
        qid = sample.split('\t')[0]
        f.write(qid + '\t' + str(predicts[idx]) + '\n')
    f.close()
```

## 2. ç›®æ ‡çº§æƒ…æ„Ÿåˆ†æ
ç›®æ ‡çº§æƒ…æ„Ÿåˆ†æå°†å¯¹æ•´å¥çš„æƒ…æ„Ÿå€¾å‘æ‰©å……ä¸ºå¯¹å¤šä¸ªç‰¹å®šå±æ€§çš„æƒ…æ„Ÿå€¾å‘ï¼Œæœ¬è´¨ä¸Šä»ç„¶æ˜¯åºåˆ—åˆ†ç±»ï¼Œä½†æ˜¯é’ˆå¯¹åŒä¸€ä¸ªåºåˆ—éœ€è¦è¿›è¡Œå¤šæ¬¡åˆ†ç±»ï¼Œé’ˆå¯¹ä¸åŒçš„å±æ€§ã€‚è¿™é‡Œçš„æ€è·¯æ˜¯å°†é’ˆå¯¹çš„å±æ€§ä¹Ÿä½œä¸ºè¾“å…¥çš„ä¸€éƒ¨åˆ†ä¼ å…¥æ¨¡å‹ï¼Œå¹¶é¢„æµ‹æƒ…æ„Ÿå€¾å‘ã€‚

### 2.0 è½½å…¥æ¨¡å‹å’ŒTokenizer


```python
import paddlenlp
from paddlenlp.transformers import SkepForSequenceClassification, SkepTokenizer
```

### 2.1 æ•°æ®å¤„ç†


```python
# è§£å‹æ•°æ®
!unzip -o data/data95319/SE-ABSA16_CAME
!unzip -o data/data95319/SE-ABSA16_PHNS
```

æ•°æ®å†…éƒ¨ç»“æ„è§£æï¼ˆä¸¤ä¸ªæ•°æ®é›†çš„ç»“æ„ç›¸åŒï¼‰ï¼š
```
train:
label		text_a		text_b
1		phone#design_features		ä»Šå¤©æœ‰å¹¸æ‹¿åˆ°äº†æ¸¯ç‰ˆç™½è‰²iPhone 5çœŸæœºï¼Œè¯•ç©äº†ä¸€ä¸‹ï¼Œè¯´è¯´æ„Ÿå—å§ï¼š1. çœŸæœºå°ºå¯¸å®½åº¦ä¸4/4sä¿æŒä¸€è‡´æ²¡æœ‰å˜åŒ–...
0		software#operation_performance		è‹¹æœiPhone5æ–°æœºåˆ°æ‰‹ å¯¹æ¯”4Sä½¿ç”¨æ„Ÿå—1ï¼Œå¤–è§‚ã€‚ä¸€å¼€å§‹çœ‹å‘å¸ƒä¼šå’Œç½‘ä¸Šç…§ç‰‡ï¼Œæˆ‘å’Œå¤§å¤šæ•°äººè§‚ç‚¹ä¸€æ ·ï¼šå˜åŒ–ä¸å¤§ï¼Œæœ‰ç‚¹å°å¤±æœ›ã€‚...

test:
qid		text_a		text_b
0		software#usability		åˆšåˆšå…¥æ‰‹8600ï¼Œä½“ä¼šã€‚åˆšåˆšä»æ·˜å®è´­ä¹°ï¼Œ1635å…ƒï¼ˆåŒ…é‚®ï¼‰ã€‚1ã€å…¨æ–°ï¼Œ...
...		...		...


```python
# å¾—åˆ°æ•°æ®é›†å­—å…¸
# å¾—åˆ°æ•°æ®é›†å­—å…¸
def open_func(file_path):
    return [line.strip() for line in open(file_path, 'r', encoding='utf8').readlines()[1:] if len(line.strip().split('\t')) >= 2]

data_dict = {'seabsa16phns': {'test': open_func('SE-ABSA16_PHNS/test.tsv'),
                              'train': open_func('SE-ABSA16_PHNS/train.tsv')},
             'seabsa16came': {'test': open_func('SE-ABSA16_CAME/test.tsv'),
                              'train': open_func('SE-ABSA16_CAME/train.tsv')}}
```

### 2.2 å®šä¹‰æ•°æ®è¯»å–å™¨
æ–¹æ³•ä¸1.2ä¸­ç›¸ä¼¼ï¼ŒåŸºæœ¬æ˜¯å®Œå…¨ç²˜è´´å¤åˆ¶è¿‡æ¥å³å¯ã€‚è¿™é‡Œæ³¨æ„éœ€è¦ä¸¤ä¸ªtextï¼Œå¹¶ä¸”è¦è€ƒè™‘token_type_idäº†ã€‚


```python
# å®šä¹‰æ•°æ®é›†
from paddle.io import Dataset, DataLoader
from paddlenlp.data import Pad, Stack, Tuple
import numpy as np
label_list = [0, 1]

# è€ƒè™‘token_type_id
class MyDataset(Dataset):
    def __init__(self, data, tokenizer, max_len=512, for_test=False):
        super().__init__()
        self._data = data
        self._tokenizer = tokenizer
        self._max_len = max_len
        self._for_test = for_test
    
    def __len__(self):
        return len(self._data)
    
    def __getitem__(self, idx):
        samples = self._data[idx].split('\t')
        label = samples[-3]
        text_b = samples[-1]
        text_a = samples[-2]
        label = int(label)
        encoder_out = self._tokenizer.encode(text_a, text_b, max_seq_len=self._max_len)
        text = encoder_out['input_ids']
        token_type = encoder_out['token_type_ids']
        if self._for_test:
            return np.array(text, dtype='int64'), np.array(token_type, dtype='int64')
        else:
            return np.array(text, dtype='int64'), np.array(token_type, dtype='int64'), np.array(label, dtype='int64')

def batchify_fn(for_test=False):
    if for_test:
        return lambda samples, fn=Tuple(Pad(axis=0, pad_val=tokenizer.pad_token_id),
                                        Pad(axis=0, pad_val=tokenizer.pad_token_type_id)): [data for data in fn(samples)]
    else:
        return lambda samples, fn=Tuple(Pad(axis=0, pad_val=tokenizer.pad_token_id),
                                        Pad(axis=0, pad_val=tokenizer.pad_token_type_id),
                                        Stack()): [data for data in fn(samples)]


def get_data_loader(data, tokenizer, batch_size=32, max_len=512, for_test=False):
    dataset = MyDataset(data, tokenizer, max_len, for_test)
    shuffle = True if not for_test else False
    data_loader = DataLoader(dataset=dataset, batch_size=batch_size, collate_fn=batchify_fn(for_test), shuffle=shuffle)
    return data_loader
```

### 2.3 æ¨¡å‹æ­å»ºå¹¶è¿›è¡Œè®­ç»ƒ
æŠŠ1.3çš„å¤åˆ¶ç²˜è´´è¿‡æ¥ï¼Œæ³¨æ„è¯¥æ•°æ®é›†åç§°ï¼Œå¹¶åŠ ä¸Šä¸€ä¸ªtoken_type_idçš„è¾“å…¥ã€‚


```python
import paddle
from paddle.static import InputSpec

# æ¨¡å‹å’Œåˆ†è¯
model = SkepForSequenceClassification.from_pretrained('skep_ernie_1.0_large_ch', num_classes=2)
tokenizer = SkepTokenizer.from_pretrained('skep_ernie_1.0_large_ch')

# å‚æ•°è®¾ç½®
data_name = 'seabsa16phns'  # æ›´æ”¹æ­¤é€‰é¡¹æ”¹å˜æ•°æ®é›†

## è®­ç»ƒç›¸å…³
epochs = 10
learning_rate = 5e-6
batch_size = 8
max_len = 512

## æ•°æ®ç›¸å…³
train_dataloader = get_data_loader(data_dict[data_name]['train'], tokenizer, batch_size, max_len, for_test=False)

input = InputSpec((-1, -1), dtype='int64', name='input')
token_type = InputSpec((-1, -1), dtype='int64', name='token_type')
label = InputSpec((-1, 2), dtype='int64', name='label')
model = paddle.Model(model, [input, token_type], [label])

# æ¨¡å‹å‡†å¤‡
# åŠ å…¥è¿‡æ‹Ÿåˆ æ­£åˆ™åŒ– 
optimizer = paddle.optimizer.Adam(learning_rate=learning_rate,weight_decay=paddle.regularizer.L2Decay(coeff=1e-5),parameters=model.parameters())
model.prepare(optimizer, loss=paddle.nn.CrossEntropyLoss(), metrics=[paddle.metric.Accuracy()])
```


```python
# å¼€å§‹è®­ç»ƒ
model.fit(train_dataloader, batch_size=batch_size, epochs=epochs, save_freq=5, save_dir='./checkpoints', log_freq=200)
```

### 2.4 é¢„æµ‹å¹¶ä¿å­˜


```python
# å¯¼å…¥é¢„è®­ç»ƒæ¨¡å‹
checkpoint_path = './checkpoints/final'  # å¡«å†™é¢„è®­ç»ƒæ¨¡å‹çš„ä¿å­˜è·¯å¾„

model = SkepForSequenceClassification.from_pretrained('skep_ernie_1.0_large_ch', num_classes=2)
input = InputSpec((-1, -1), dtype='int64', name='input')
token_type = InputSpec((-1, -1), dtype='int64', name='token_type')
model = paddle.Model(model, [input, token_type])
model.load(checkpoint_path)

# å¯¼å…¥æµ‹è¯•é›†
test_dataloader = get_data_loader(data_dict[data_name]['test'], tokenizer, batch_size, max_len, for_test=True)
# é¢„æµ‹ä¿å­˜

save_file = {'seabsa16phns': './submission/SE-ABSA16_PHNS.tsv', 'seabsa16came': './submission/SE-ABSA16_CAME.tsv'}
predicts = []
for batch in test_dataloader:
    predict = model.predict_batch(batch)
    predicts += predict[0].argmax(axis=-1).tolist()

with open(save_file[data_name], 'w', encoding='utf8') as f:
    f.write("index\tprediction\n")
    for idx, sample in enumerate(data_dict[data_name]['test']):
        qid = sample.split('\t')[0]
        f.write(qid + '\t' + str(predicts[idx]) + '\n')
    f.close()
```

## 3. è§‚ç‚¹æŠ½å–
### 3.0 è½½å…¥æ¨¡å‹å’ŒTokenizer


```python
import paddlenlp
from paddlenlp.transformers import SkepForTokenClassification, SkepTokenizer
```

### 3.1 æ•°æ®å¤„ç†


```python
# è§£å‹æ•°æ®
!unzip -o data/data95319/COTE-BD
!unzip -o data/data95319/COTE-DP
!unzip -o data/data95319/COTE-MFW
```

æ•°æ®å†…éƒ¨ç»“æ„è§£æï¼ˆä¸‰ä¸ªæ•°æ®é›†çš„ç»“æ„ç›¸åŒï¼‰ï¼š
```
train:
label		text_a
é¸Ÿäºº		ã€Šé¸Ÿäººã€‹ä¸€ä¹¦ä»¥é¸Ÿåšå£«çš„é­é‡ä½œä¸ºä¸»çº¿ï¼Œä¸»è¦å†™äº†é¸Ÿåšå£«ä»æ ¡å›­å‡ºæ¥åçš„ç§ç§è’è¯ç»å†ã€‚
...		...
test:
qid		text_a
0		æ¯•æ£šæ²Ÿçš„é£æ™¯æ—©æœ‰æ‰€é—»ï¼Œå°¤å…¶ä»¥ç§‹å­£çš„é£æ™¯æœ€ç¾ï¼Œä½†æ˜¯è¿™æ¬¡å»æ™šäº†ï¼Œçº¢å¶å…¨æ‰å®Œäº†ï¼Œé»„å¶ä¹Ÿçœ‹ä¸åˆ°äº†ï¼Œä¸‹äº†é›ªåª...
...		...


```python
# å¾—åˆ°æ•°æ®é›†å­—å…¸
def open_func(file_path):
    return [line.strip() for line in open(file_path, 'r', encoding='utf8').readlines()[1:] if len(line.strip().split('\t')) >= 2]

data_dict = {'cotebd': {'test': open_func('COTE-BD/test.tsv'),
                        'train': open_func('COTE-BD/train.tsv')},
             'cotedp': {'test': open_func('COTE-DP/test.tsv'),
                        'train': open_func('COTE-DP/train.tsv')},
             'cotemfw': {'test': open_func('COTE-MFW/test.tsv'),
                        'train': open_func('COTE-MFW/train.tsv')}}
```

### 3.2 å®šä¹‰æ•°æ®è¯»å–å™¨
æ€è·¯ç±»ä¼¼ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯è¿™ä¸€æ¬¡æ˜¯Tokensçº§çš„åˆ†ç±»ã€‚åœ¨æ•°æ®è¯»å–å™¨ä¸­ï¼Œå°†labelå†™æˆBIOçš„å½¢å¼ï¼Œæ¯ä¸€ä¸ªtokenéƒ½å¯¹åº”ä¸€ä¸ªlabelã€‚


```python
# å®šä¹‰æ•°æ®é›†
from paddle.io import Dataset, DataLoader
from paddlenlp.data import Pad, Stack, Tuple
import numpy as np
label_list = {'B': 0, 'I': 1, 'O': 2}
index2label = {0: 'B', 1: 'I', 2: 'O'}

# è€ƒè™‘token_type_id
class MyDataset(Dataset):
    def __init__(self, data, tokenizer, max_len=512, for_test=False):
        super().__init__()
        self._data = data
        self._tokenizer = tokenizer
        self._max_len = max_len
        self._for_test = for_test
    
    def __len__(self):
        return len(self._data)
    
    def __getitem__(self, idx):
        samples = self._data[idx].split('\t')
        label = samples[-2]
        text = samples[-1]
        if self._for_test:
            origin_enc = self._tokenizer.encode(text, max_seq_len=self._max_len)['input_ids']
            return np.array(origin_enc, dtype='int64')
        else:
            
            # ç”±äºå¹¶ä¸æ˜¯æ¯ä¸ªå­—éƒ½æ˜¯ä¸€ä¸ªtokenï¼Œè¿™é‡Œé‡‡ç”¨ä¸€ç§ç®€å•çš„å¤„ç†æ–¹æ³•ï¼Œå…ˆç¼–ç labelï¼Œå†ç¼–ç textä¸­é™¤äº†labelä»¥å¤–çš„è¯ï¼Œæœ€ååˆåˆ°ä¸€èµ·
            texts = text.split(label)
            label_enc = self._tokenizer.encode(label)['input_ids']
            cls_enc = label_enc[0]
            sep_enc = label_enc[-1]
            label_enc = label_enc[1:-1]
            
            # åˆå¹¶
            origin_enc = []
            label_ids = []
            for index, text in enumerate(texts):
                text_enc = self._tokenizer.encode(text)['input_ids']
                text_enc = text_enc[1:-1]
                origin_enc += text_enc
                label_ids += [label_list['O']] * len(text_enc)
                if index != len(texts) - 1:
                    origin_enc += label_enc
                    label_ids += [label_list['B']] + [label_list['I']] * (len(label_enc) - 1)

            origin_enc = [cls_enc] + origin_enc + [sep_enc]
            label_ids = [label_list['O']] + label_ids + [label_list['O']]
            
            # æˆªæ–­
            if len(origin_enc) > self._max_len:
                origin_enc = origin_enc[:self._max_len-1] + origin_enc[-1:]
                label_ids = label_ids[:self._max_len-1] + label_ids[-1:]
            return np.array(origin_enc, dtype='int64'), np.array(label_ids, dtype='int64')


def batchify_fn(for_test=False):
    if for_test:
        return lambda samples, fn=Pad(axis=0, pad_val=tokenizer.pad_token_id): np.row_stack([data for data in fn(samples)])
    else:
        return lambda samples, fn=Tuple(Pad(axis=0, pad_val=tokenizer.pad_token_id),
                                        Pad(axis=0, pad_val=label_list['O'])): [data for data in fn(samples)]


def get_data_loader(data, tokenizer, batch_size=32, max_len=512, for_test=False):
    dataset = MyDataset(data, tokenizer, max_len, for_test)
    shuffle = True if not for_test else False
    data_loader = DataLoader(dataset=dataset, batch_size=batch_size, collate_fn=batchify_fn(for_test), shuffle=shuffle)
    return data_loader
```

### 3.3 æ¨¡å‹æ­å»ºå¹¶è¿›è¡Œè®­ç»ƒ
ä¸ä¹‹å‰ä¸åŒçš„æ˜¯æ¨¡å‹æ¢æˆäº†Tokenåˆ†ç±»ã€‚ç”±äºAccuracyä¸å†é€‚ç”¨äºTokenåˆ†ç±»ï¼Œæˆ‘ä»¬ç”¨Perplexityæ¥å¤§è‡´è¡¡é‡é¢„æµ‹çš„å‡†ç¡®åº¦ï¼ˆæ¥è¿‘1ä¸ºæœ€ä½³ï¼‰ã€‚


```python
import paddle
from paddle.static import InputSpec
from paddlenlp.metrics import Perplexity

# æ¨¡å‹å’Œåˆ†è¯
model = SkepForTokenClassification.from_pretrained('skep_ernie_1.0_large_ch', num_classes=3)
tokenizer = SkepTokenizer.from_pretrained('skep_ernie_1.0_large_ch')

# å‚æ•°è®¾ç½®
data_name = 'cotemfw'  # æ›´æ”¹æ­¤é€‰é¡¹æ”¹å˜æ•°æ®é›†

## è®­ç»ƒç›¸å…³
epochs = 10
learning_rate = 5e-6
batch_size = 8
max_len = 512

## æ•°æ®ç›¸å…³
train_dataloader = get_data_loader(data_dict[data_name]['train'], tokenizer, batch_size, max_len, for_test=False)

input = InputSpec((-1, -1), dtype='int64', name='input')
label = InputSpec((-1, -1, 3), dtype='int64', name='label')
model = paddle.Model(model, [input], [label])

# æ¨¡å‹å‡†å¤‡
# åŠ å…¥è¿‡æ‹Ÿåˆ æ­£åˆ™åŒ– 
optimizer = paddle.optimizer.Adam(learning_rate=learning_rate,weight_decay=paddle.regularizer.L2Decay(coeff=1e-5),parameters=model.parameters())
model.prepare(optimizer, loss=paddle.nn.CrossEntropyLoss(), metrics=[Perplexity()])
```

    [2021-06-21 15:24:20,369] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/skep_ernie_1.0_large_ch/skep_ernie_1.0_large_ch.pdparams
    [2021-06-21 15:24:25,086] [    INFO] - Found /home/aistudio/.paddlenlp/models/skep_ernie_1.0_large_ch/skep_ernie_1.0_large_ch.vocab.txt



```python
from visualdl import LogWriter
log_writer = LogWriter("./log")
# å®‰è£…VisualDL
!pip install --upgrade --pre visualdl
```


```python
# å¼€å§‹è®­ç»ƒ
model.fit(train_dataloader,
        batch_size=batch_size,
        epochs=epochs,
        save_freq=2,
        save_dir='./checkpoints/cotemfw',
        log_freq=200)
```

### 3.4 é¢„æµ‹å¹¶ä¿å­˜


```python
# å¯¼å…¥é¢„è®­ç»ƒæ¨¡å‹
checkpoint_path = './checkpoints/cotemfw/final'  # å¡«å†™é¢„è®­ç»ƒæ¨¡å‹çš„ä¿å­˜è·¯å¾„

model = SkepForTokenClassification.from_pretrained('skep_ernie_1.0_large_ch', num_classes=3)
input = InputSpec((-1, -1), dtype='int64', name='input')
model = paddle.Model(model, [input])
model.load(checkpoint_path)

# å¯¼å…¥æµ‹è¯•é›†
test_dataloader = get_data_loader(data_dict[data_name]['test'], tokenizer, batch_size, max_len, for_test=True)
# é¢„æµ‹ä¿å­˜

save_file = {'cotebd': './submission/COTE_BD.tsv', 'cotedp': './submission/COTE_DP.tsv', 'cotemfw': './submission/COTE_MFW.tsv'}
predicts = []
input_ids = []
for batch in test_dataloader:
    predict = model.predict_batch(batch)
    predicts += predict[0].argmax(axis=-1).tolist()
    input_ids += batch.numpy().tolist()

# å…ˆæ‰¾åˆ°Bæ‰€åœ¨çš„ä½ç½®ï¼Œå³æ ‡å·ä¸º0çš„ä½ç½®ï¼Œç„¶åé¡ºç€è¯¥ä½ç½®ä¸€ç›´æ‰¾åˆ°æ‰€æœ‰çš„Iï¼Œå³æ ‡å·ä¸º1ï¼Œå³ä¸ºæ‰€å¾—ã€‚
def find_entity(prediction, input_ids):
    entity = []
    entity_ids = []
    for index, idx in enumerate(prediction):
        if idx == label_list['B']:
            entity_ids = [input_ids[index]]
        elif idx == label_list['I']:
            if entity_ids:
                entity_ids.append(input_ids[index])
        elif idx == label_list['O']:
            if entity_ids:
                entity.append(''.join(tokenizer.convert_ids_to_tokens(entity_ids)))
                entity_ids = []
    return entity

import re

with open(save_file[data_name], 'w', encoding='utf8') as f:
    f.write("index\tprediction\n")
    for idx, sample in enumerate(data_dict[data_name]['test']):
        qid = sample.split('\t')[0]
        entity = find_entity(predicts[idx], input_ids[idx])
        entity = list(set(entity))  # å»é‡
        entity = [re.sub('##', '', e) for e in entity]  # å»é™¤è‹±æ–‡ç¼–ç æ—¶çš„ç‰¹æ®Šç¬¦å·
        entity = [re.sub('[UNK]', '', e) for e in entity]  # å»é™¤æœªçŸ¥ç¬¦å·
        f.write(qid + '\t' + '\x01'.join(entity) + '\n')
    f.close()
```

    [2021-06-21 18:41:25,893] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/skep_ernie_1.0_large_ch/skep_ernie_1.0_large_ch.pdparams


# æ€»ç»“

é¡¹ç›®ä¸»è¦è¿˜æ˜¯ä»¥[é—«ä½¬çš„é¡¹ç›®------å®è·µè¯¾5-æƒ…æ„Ÿåˆ†æBaseline](https://aistudio.baidu.com/aistudio/projectdetail/2085599)ä¸ºä¸»è¿›è¡Œäº†å‚æ•°çš„è°ƒæ•´ã€‚

åŸºäºåŸbaselineä¸Šçš„æ›´æ”¹ç‚¹
1. æ›´æ”¹äº†å­¦ä¹ ç‡
2. æ›´æ”¹äº†epoch
3. æ·»åŠ äº†é˜²æ­¢è¿‡æ‹Ÿåˆçš„æ­£åˆ™åŒ–é¡¹

æœ€ç»ˆå›¢é˜Ÿä¸ƒä¸ªæ•°æ®é›†çš„é¡¹ç›®æ€»åˆ†è¾¾åˆ°äº†0.81å·¦å³

å»ºè®®
1. è·‘ä¹‹å‰ï¼Œåœ¨å·¦ä¾§çª—å£**æ–°å»ºä¸€ä¸ªsubmissionæ–‡ä»¶å¤¹**ï¼Œä¸ç„¶åç»­ä¼šæŠ¥é”™ï¼Œé‡åˆ°å°±æ‡‚äº† 
2. æ¯è·‘ä¸€ä¸ªæ•°æ®é›†ï¼Œé‡å¯ä¸€æ¬¡é¡¹ç›®ï¼Œé˜²æ­¢æ˜¾å­˜æº¢å‡ºã€‚
3. å°†æ¯ä¸ªæ•°æ®é›†è‡ªå·±æ–°å»ºä¸€ä¸ªæ–‡ä»¶è¿›è¡Œå­˜å‚¨ç”Ÿæˆçš„æ¨¡å‹ï¼Œé˜²æ­¢æ‰€æœ‰çš„æ•°æ®é›†çš„æ¨¡å‹åœ¨ä¸€å—æ··ä¹±ã€‚

æˆ‘åœ¨AI Studioä¸Šè·å¾—é’»çŸ³ç­‰çº§ï¼Œç‚¹äº®8ä¸ªå¾½ç« ï¼Œæ¥äº’å…³å‘€~ 

https://aistudio.baidu.com/aistudio/personalcenter/thirdview/643467
